---
layout: ../../../layouts/BlogPost.astro
title: "CallKaro"
date: "February 17, 2026"
type: project
description: "An offline voice AI agent that calls local vendors in Hindi and collects competitive quotes for consumer electronics."
titleLinkText: "CallKaro"
titleLinkUrl: https://callkaro.nikamma.in
---

# CallKaro: Agent to Call Indian Shops and Haggle in Hindi

*A full-stack voice pipeline that researches products, finds local stores, calls them in Hindi, negotiates prices, and compares quotes â€” autonomously.*

In India, if you want to buy an air conditioner, a washing machine, or a refrigerator, you do not go to a website and click "Add to Cart." You call three or four local dealers, ask for their best price, mention that the shop down the road offered you less, and eventually settle on a number. This ritual plays out millions of times a day across the country, entirely over the phone, entirely in Hindi.

I built CallKaro to automate that ritual. It is a voice AI agent that calls real shops, speaks Hindi, asks about prices, pushes back gently on high quotes, and compares results across stores. This post covers how it works, what broke along the way, and the technical decisions that made it possible.

## Why Indian Electronics Prices Don't Exist Online

Three realities define consumer electronics retail in India:

**Local dealers do not list prices online**<br/>
Walk into any appliance market -- Lajpat Rai in Delhi, SP Road in Bangalore, Lamington Road in Mumbai -- and you will find hundreds of shops. Almost none of them publish prices. The price depends on who is asking, what day it is, and how much inventory they have.

**Negotiation is expected**<br/>
The first price a shopkeeper quotes is never the final price. Buyers are expected to push back. Mentioning a competitor's quote or simply saying "thoda zyada lag raha hai" (seems a bit high) can shave thousands of rupees off.

**Hindi-first market**<br/>
Over 600 million people in India speak Hindi. In Tier 2 and Tier 3 cities, most shopkeepers conduct business exclusively in Hindi. A price enquiry system that only works in English misses the majority of the market.

CallKaro addresses all three: it makes real phone calls, negotiates in natural Hindi, and aggregates results across multiple shops into a structured comparison.

## Five Stages: From "I Want an AC" to a Price Comparison

The system is a five-stage pipeline. A user says what they want to buy and where they live. CallKaro researches the product, finds nearby stores, calls each one, and presents a ranked comparison.

**Stage 1: Intake**<br/>
An LLM extracts structured requirements from natural language -- product type, capacity, budget, location, brand preferences.

**Stage 2: Research**<br/>
Web search for current market prices, dealer margins, seasonal pricing, and negotiation tactics. This intelligence gets injected into the voice agent's system prompt so it can push back credibly.

**Stage 3: Store Discovery**<br/>
Google Maps scraping and web search find nearby stores, phone numbers, ratings, and reviews.

**Stage 4: Voice Calling**<br/>
For each store, CallKaro spins up a LiveKit WebRTC room, dispatches a voice agent, and dials the store over SIP. The agent speaks Hindi, asks about price, warranty, installation, delivery, negotiates gently, and hangs up once it has enough information.

**Stage 5: Cross-Store Analysis**<br/>
Transcripts are fed to an LLM that extracts structured data and ranks stores by total estimated cost.

## How the Voice Pipeline Turns Phone Audio Into Hindi Conversation

Here is the signal flow for a single conversational turn:

**VAD (Silero)**<br/>
Detects when someone is speaking. I tuned `min_speech_duration` to 80ms and `min_silence_duration` to 800ms so the agent waits a beat before assuming the shopkeeper has finished.

**STT (Sarvam saaras:v3)**<br/>
Converts Hindi speech to English-transliterated text -- "Adtees hazaar ka hai" rather than Devanagari script.

**LLM (Claude Haiku 4.5)**<br/>
Receives the shopkeeper's transcribed speech and generates the next response in Romanized Hindi.

**Normalization Layer**<br/>
Sits between the LLM and TTS. Handles number-to-Hindi-word conversion, Devanagari transliteration, action marker stripping, and spacing fixes. This is where most of the bugs lived.

**TTS (Sarvam bulbul:v3)**<br/>
Converts Romanized Hindi text to natural-sounding Hindi speech. The "shubh" voice at 8kHz for telephony, 16kHz for browser sessions.

**Turn Detection**<br/>
A transformer-based model that predicts end-of-utterance using conversation context, running on top of VAD signals. Critical for Hindi, where pauses mid-sentence are common.

## Six Bugs I Hit While Making an AI Speak Hindi on the Phone

### Streaming Broke Hindi Numbers: "28" + "000" Became "28" and "Zero"

LLM responses arrive as token chunks. The number "28000" might arrive as `"28"` and `"000"`. Normalizing each chunk independently produces "attaaees" (28) followed by "zero" instead of "attaaees hazaar" (28,000).

The fix is a buffered normalizer that holds trailing digits until the next chunk arrives:

```python
class _NumberBufferedNormalizer:
    def __init__(self):
        self._buffer = ""

    def process(self, chunk: str) -> str:
        chunk = self._buffer + chunk
        self._buffer = ""
        m = re.search(r"(\d+)$", chunk)
        if m:
            self._buffer = m.group(1)
            chunk = chunk[:m.start()]
        return _normalize_for_tts(chunk) if chunk else ""

    def flush(self) -> str:
        if self._buffer:
            result = _normalize_for_tts(self._buffer)
            self._buffer = ""
            return result
        return ""
```

Hindi number conversion covers every number from 0 to 99 with individual words (Hindi does not have a regular tens-and-ones pattern like English), plus compound forms for thousands, lakhs, and crores. It also handles special patterns: 1,500 becomes "dedh hazaar" (one-and-a-half thousand), 2,500 becomes "dhaai hazaar", and 37,500 becomes "saadhe saintees hazaar".

### The LLM Would Randomly Switch to English Mid-Call

Occasionally the LLM would respond in fluent English instead of Romanized Hindi, crashing the Hindi TTS. I built a heuristic detector that checks for the presence of common Hindi marker words (`achha`, `ji`, `haan`, `theek`, `kya`, `hai`, etc.). If a response longer than 20 characters contains none of them, it is flagged as a character break and a canned Hindi fallback is used instead.

### Background Noise Transcribed as "Table" and "The" Triggered False Replies

The Sarvam STT model would sometimes transcribe silence, hold music, or line noise as random English words -- "table," "the," "and" -- triggering the LLM to respond to phantom input. Single-word transcripts matching a known set of common STT artifacts get flagged as garbage and ignored.

### Hindi Script Characters Leaked Into Latin-Only TTS and Crashed It

Despite explicit instructions to output only Romanized Hindi, the LLM would occasionally leak Devanagari characters. A fast single-pass transliterator detects and converts any Devanagari to its Romanized equivalent, handling consonant-matra combinations correctly.

### The Agent Said Hello Twice Because the LLM Forgot It Already Spoke

The agent speaks a greeting when joining a call, which is added to the chat context so the LLM sees it as its own first message. The problem: the LLM would then generate the exact same greeting again. The fix was a NOTE injected into the system prompt with the exact greeting text, telling the LLM to continue from the shopkeeper's response instead of re-greeting.

### Stripping Whitespace Killed Natural Pauses in Speech

The Sarvam TTS engine uses whitespace patterns to split text into sentences for prosody. When the normalization layer called `.strip()` on LLM output chunks, it removed leading spaces that acted as sentence boundary signals, producing unnatural run-together speech. The fix: preserve all whitespace from LLM tokens through the entire pipeline.

## Sarvam STT/TTS: Monkey-Patches, Preprocessing, and Audio Settings

**STT WebSocket reconnection**<br/>
The Sarvam STT WebSocket connection dies after ~90 seconds because the LiveKit plugin's `_run()` method breaks on normal stream completion instead of reconnecting. I monkey-patched `SpeechStream._run` to loop and reconnect until the session truly ends.

**TTS preprocessing**<br/>
Sarvam's `enable_preprocessing=True` handles Romanized Hindi pronunciation internally, so no custom pronunciation dictionary is needed. I use the "shubh" male voice at 8kHz for telephony, 16kHz for browser testing.

**Audio parameters**<br/>
Phone calls run at 8kHz (standard telephony), browser sessions at 16kHz. The voice agent dynamically selects the sample rate based on whether a phone number is present in the call metadata.

## Testing a Hindi Voice Agent: Simulated Shopkeepers and 188 Unit Tests

### Layer 1: Shopkeeper Scenario Simulation

I created 11 scripted shopkeeper scenarios derived from real call transcripts. Each scenario has a personality: cooperative shopkeepers who give prices directly, defensive ones who refuse to negotiate, evasive ones who go off-topic, ones who put you on hold, and ones who interrupt frequently. The test framework feeds shopkeeper lines one at a time into the actual LLM and validates the agent's response after each turn.

### Layer 2: ConstraintChecker (8 Rules)

Every agent response is checked against 8 behavioral constraints:

1. **No Devanagari** -- Hindi script characters crash the TTS
2. **Single question** -- no stacking 3 questions in one breath
3. **Response length** -- under 300 characters
4. **No action markers** -- no `*pauses*` or `(laughs)` text
5. **No newlines** -- TTS reads everything as one utterance
6. **No English translations** -- no `(Yes, I'm listening)` parentheticals
7. **No end_call text** -- use the tool, do not type `[end_call]`
8. **No invented details** -- do not fabricate specific brands or addresses

### Layer 3: ConversationScorer (Weighted Scoring)

Full conversations are scored on five dimensions:

| Dimension | Weight | What It Measures |
|---|---|---|
| Constraints | 40% | Average ConstraintChecker score across all turns |
| Topic coverage | 25% | How many of price/warranty/installation/delivery/exchange were discussed |
| Price echo | 15% | Did the agent repeat the shopkeeper's exact price number back |
| Brevity | 10% | Average response length (under 100 chars = perfect) |
| No repetition | 10% | Adjacent responses are not copies of each other |

The full test suite has 188 unit tests covering normalization, sanitization, transcript parsing, store ranking, prompt building, and constraint checking, plus 26 live API tests that hit the actual Sarvam and Anthropic endpoints.

## A Real Call Transcript: 6 Turns, Score 0.91

A condensed transcript from a real call to a local AC dealer in Bangalore:

```
Agent:  "Hello, yeh Pai Electronics hai? 1.5 ton split AC ke
         baare mein poochna tha."
Shop:   "Haan ji, Samsung hai. Boliye."
Agent:  "Bhaisaab, dedh ton ka paanch star inverter split AC
         ka best price kya doge?"
Shop:   "Adtees hazaar ka hai."
Agent:  "Achha, untaalees hazaar. Installation free hai kya?"
Shop:   "Installation free hai, hum apne aadmi bhejte hain."
Agent:  "Theek hai. Warranty kitni milegi?"
Shop:   "Ek saal company ki, aur compressor pe paanch saal."
Agent:  "Achha ek saal. Main 2-3 shops se rate le raha hoon.
         Thoda kam ho sakta hai?"
Shop:   "Nahi bhai, best price hai yeh."
Agent:  "Theek hai ji. Delivery kitne din mein hogi?"
Shop:   "Do-teen din mein laga denge. Stock mein hai."
Agent:  "Theek hai ji, bahut badiya. Dhanyavaad, namaste."
         [end_call tool invoked]
```

Overall score 0.91, all 8 constraints passed, topics covered: price, installation, warranty, delivery. On the 11-scenario test suite, the agent consistently scores above 0.85 with constraint compliance above 0.95.

## Next: Smarter Negotiation, Voice A/B Tests, Product-Specific Flows

**Negotiation intelligence**<br/>
Phase 2 will use researched dealer margins and online reference prices more aggressively during calls -- dynamically adjusting negotiation pressure based on how the quoted price compares to the market range.

**Voice A/B testing**<br/>
Sarvam's bulbul:v3 has 39 available speakers. I want to test whether different voices (male vs female, formal vs casual) affect the prices shopkeepers quote. The hypothesis: voice characteristics influence perceived social status, which affects the starting price.

**Product-specific conversation flows**<br/>
Right now the agent uses a generic conversation structure. An AC purchase involves tonnage and copper piping costs; a washing machine involves load capacity and drum type; a laptop involves use case and RAM. Phase 2 will have product-specific conversation trees.

---

*CallKaro is live at [callkaro.nikamma.in](https://callkaro.nikamma.in). The code is on [GitHub](https://github.com/dewanggogte/callkaro). The stack is LiveKit for WebRTC, Sarvam AI for Hindi STT/TTS, Claude Haiku 4.5 for the LLM, and a plain Python HTTP server holding it all together.*
